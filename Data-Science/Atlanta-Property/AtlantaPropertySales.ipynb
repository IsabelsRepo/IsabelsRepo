{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07537feb-f718-43ac-881f-52143f0f8f01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd              # v2.0.1\n",
    "import numpy as np               # v1.24.3\n",
    "import matplotlib.pyplot as plt  # v3.7.1\n",
    "import folium                    # v0.14.0\n",
    "# adding a comment to test git integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0eb980bd-c813-49ef-be7c-eb6fa2062918",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'CleanedAtlantaPropertyData_2009-2022.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m col_type \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTaxYear\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint16\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTotAppr\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint32\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTotAssess\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint32\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLandAppr\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint32\u001b[39m\u001b[38;5;124m'\u001b[39m}\n\u001b[1;32m----> 2\u001b[0m atlanta_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCleanedAtlantaPropertyData_2009-2022.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcol_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m atlanta_df\u001b[38;5;241m.\u001b[39minfo\n",
      "File \u001b[1;32mc:\\users\\owner\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\owner\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\users\\owner\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\owner\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1662\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1663\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1666\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1668\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1670\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\users\\owner\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\io\\common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    863\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'CleanedAtlantaPropertyData_2009-2022.csv'"
     ]
    }
   ],
   "source": [
    "col_type = {'TaxYear' : 'int16', 'TotAppr' : 'int32', 'TotAssess' : 'int32', 'LandAppr' : 'int32'}\n",
    "atlanta_df = pd.read_csv(r'CleanedAtlantaPropertyData_2009-2022.csv', sep=',', dtype=col_type)\n",
    "atlanta_df.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5eca1a1-941e-4a4a-83ad-361e3b2cdd46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5819f0b9-e449-44ec-8691-0704ac1e6408",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Only finds sales where the owner left atlanta the next tax year\n",
    "def parcel_sale(df_list):\n",
    "    ''' returns parcels sold where owner left Atlanta in a given year'''\n",
    "    # feels like a kludgey way to select the next element\n",
    "    i = 0\n",
    "    leave_df = pd.DataFrame( {'ParcelID': [], 'TaxYear': []})\n",
    "    for owner in df_list:\n",
    "        n = i+1\n",
    "        if i == len(df_list)-1:\n",
    "            return sales_df\n",
    "        else:\n",
    "            sales = owner[owner['Owner'].isin(df_list[n]['Owner']) == False]\n",
    "            leave_df = pd.concat([leave_df, sales[['ParcelID', 'TaxYear', 'TaxDist', 'TotAssess',\n",
    "                                                   'TotAppr', 'LivUnits']]])\n",
    "            i += 1     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2831e1f0-5b71-431d-8718-b42ea3ca0eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parcel_sales_refactor(df_list):\n",
    "    '''return parcels sold in a given year'''\n",
    "    sold_df = pd.DataFrame({'ParcelID':[], 'TaxYear':[]})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e826f2-d0d8-4758-8801-0da70d2e6484",
   "metadata": {},
   "outputs": [],
   "source": [
    "def year_sales(year_list, sales_df):\n",
    "    '''Takes a list of years and a dataframe of sales records and returns a dict of sales per year'''\n",
    "    sales_per_year = {}\n",
    "    for x in year_list:\n",
    "        sales_per_year[x] = len(sales_df[sales_df['TaxYear']==x])\n",
    "    return sales_per_year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25bf613-2ac7-4d26-988d-a79f8489feec",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "- [ ] which owners changed year to year\n",
    "    - [ ]  How many ['Owner']s have more than one property\n",
    "- [ ] How many parcels changed owners during a given year\n",
    "- [ ] property value year to year.\n",
    "- [ ] Bar Chart sales v time\n",
    "- [ ] Line graph property value\n",
    "- [ ] Changes in livable units\n",
    "- [ ] Local coverage of gentrification v tax records?  \n",
    "| ParcelID | Owner | TaxDist | Subdiv | TotAssess | TotAppr | LivUnits |  \n",
    "|----------|-------|---------|--------|-----------|---------|----------|  \n",
    "- [ ] Whisker plot of value by tax district  \n",
    "    - [ ] x value, y tax dist  \n",
    "    - [ ] color code data  \n",
    "        - Absolute value?  \n",
    "        - Change per year?  \n",
    "### Parcel Sales\n",
    "- [ ] Track parcel sales by year  \n",
    "        - ['PARID'] Record year of sale  \n",
    "        - Record if sale to LLC / INC / CO\n",
    "- [ ] Most sold parcel  \n",
    "- [ ] ['UNIT_NUM'] v sale frequency  \n",
    "- [ ] Single family unit sales by year  \n",
    "### Data changes\n",
    "- 2011 onward ['OWNER1'] --> ['Owner'] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93774f1-a79b-4b5a-a729-7d02101a6424",
   "metadata": {},
   "source": [
    "### parcel_sale algorithm\n",
    "- [ ] Iterate over each ['ParcelID']\n",
    "    - [ ] Check if ['Owner'] is the same  in each dataframe\n",
    "    - [ ] add parcel info to new DF if ['Owner'] changes\n",
    "#### This doesn't work how I wanted it to\n",
    "- [x] Compare 2 data frames to see if the ['Owner'] stayed the same\n",
    "    - [x] create a dataframe of [['ParcelID', 'AssessDifference']] \n",
    "    - [x] pd.concat(join='outer') sales + original dataframe\n",
    "    - [x] move on to the next set of dataframes\n",
    "    - [x] return appended dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa62a651-9c9c-4974-81b8-5cea59c4c8bf",
   "metadata": {},
   "source": [
    "### Sales Analysis\n",
    "- [x] Total number of parcels\n",
    "    - [x] Change in parcel count over time\n",
    "- [ ] Frequently sold parcels\n",
    "- [ ] Most active TaxDist\n",
    "- [ ] Highest TotAppr\n",
    "- [ ] Sales per year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0cf5e1-006c-4359-8c1d-eaf0acbcfea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find which years have data\n",
    "years = atlanta_df['TaxYear'].unique()\n",
    "# index on year. Could do drop=False but keeping the old df seems like a good idea currently.....(foreshadowing?)\n",
    "year_df = atlanta_df.set_index('TaxYear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177200e5-bbf2-467d-a202-0dc35bcce014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find properties that have changed owner in the past year.\n",
    "year_df[year_df.loc[2009]['Owner'].isin(year_df.loc[2010]['Owner']) == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89877a6d-d5f6-44b6-be3b-441d2e3c3786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset property owned by an LLC. Should expand to any company.\n",
    "# LLC, LP, CORP, \n",
    "Parcels_10[Parcels_10['Owner'].str.contains('LLC')].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351c11b8-f224-40c9-88d5-039ebacd9963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of unique companies that own property. Should expand to any company.\n",
    "# LLC, LP, CORP,\n",
    "atlanta_df[atlanta_df['Owner'].str.contains('LLC')]['Owner'].unique().size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be80a22-fbdb-4367-a967-25cf5d755f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore subdivision data\n",
    "Parcels_15['SubdivBlck'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ee59db-9077-46d7-bd25-fe12736aeb0b",
   "metadata": {},
   "source": [
    "## WTF \n",
    "- Antioch Baptist Church Of Atlanta Cemetary  \n",
    "    - Assessed to be worth $1.3B   \n",
    "    - https://iaspublicaccess.fultoncountyga.gov/Datalets/Datalet.aspx?sIndex=0&idx=1  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2887af27-173d-4ab1-bf5e-2214a02f8928",
   "metadata": {},
   "source": [
    "## This is markdown ya goof!\n",
    "year_list = [int(pd.unique(df['TaxYear'])) for df in dfs]  \n",
    "parcel_data = pd.concat(dfs, keys=[year_list])\n",
    "parcel_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d89c7739-9632-4d9e-86da-e4f7a3c4d3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame({'o': [1, 2, 3, 4, 5], 'p': [2, 3, 4, 5, 6], 'g': [3, 5, 3, 5, 2]})\n",
    "test.set_index('g', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "70d2d9bc-2b56-4c50-bb14-18f76a75b687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "g\n",
       "3    2\n",
       "3    4\n",
       "Name: p, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.loc[3]['p']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf3522e-b432-4c83-ba7f-d217011748fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2rc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
